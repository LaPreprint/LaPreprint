
@phdthesis{Andrew2018,
  title = {Design of {{Virtual Reality Systems}} for {{Animal Behavior Research}}},
  author = {Del Grosso, Nicholas Andrew and {Nicholas Andrew Del Grosso}},
  year = {2018},
  volume = {August},
  abstract = {Virtual reality (VR) experimental behavior setups enable cognitive neuroscientists to study the integration of visual depth cues and self-motion cues into a single percept of three-dimensional space.  Rodents can navigate a virtual environment by running on a spherical treadmill, but simulating locomotion in this way can both bias and suppress the frequency of their behaviors as well as introduce vestibulomotor and vestibulovisual sensory conflict during locomotion. Updating the virtual environment via the subject's own freely-moving head movements solves both the naturalistic behavior bias and vestibular conflict issues.  In this thesis, I review elements of self-motion and 3D scene perception that contribute to a sense of immersion in virtual environments and suggest a freely-moving CAVE system as a VR solution for low-artifact neuroscience experiments.  The manuscripts describing the 3D graphics Python package and the virtual reality setup are included.  In this freely-moving CAVE VR setup, freely-moving rats demonstrate immersion in virtual environments by displaying height aversion to virtual cliffs, exploration preference of virtual objects, and spontaneously modify their locomotion trajectories near virtual walls. These experiments help bridge the classic behavior and virtual reality literature by showing that rats display similar behaviors to virtual environment features without training.},
  journal = {Dissertation der Graduate School of Systemic Neurosciences der Ludwig-Maximillians-Universit\"at M\"unchen},
  keywords = {Behavior,CAVE,Spatial Perception,Virtual Reality}
}

@article{Aronov2014a,
  title = {Engagement of {{Neural Circuits Underlying 2D Spatial Navigation}} in a {{Rodent Virtual Reality System}}},
  author = {Aronov, Dmitriy and Tank, David W.},
  year = {2014},
  volume = {84},
  pages = {442--456},
  publisher = {{Elsevier Inc.}},
  issn = {10974199},
  doi = {10.1016/j.neuron.2014.08.042},
  abstract = {Virtual reality (VR) enables precise control of an animal's environment and otherwise impossible experimental manipulations. Neural activity in rodents hasbeen studied on virtual 1D tracks. However, 2D navigation imposes additional requirements, such as the processing of head direction and environment boundaries, and it is unknown whether the neural circuits underlying 2D representations can be sufficiently engaged in VR. We implemented a VR setup for rats, including software and large-scale electrophysiology, that supports 2D navigation by allowing rotation and walking in any direction. The entorhinal-hippocampal circuit, including place, head direction, and grid cells, showed 2D activity patterns similar to those in the real world. Furthermore, border cells were observed, and hippocampal remapping was driven by environment shape, suggesting functional processing of virtual boundaries. These results illustrate that 2D spatial representations can be engaged by visual and rotational vestibular stimuli alone and suggest a novel VR tool for studying rat navigation.},
  journal = {Neuron},
  number = {2},
  pmid = {25374363}
}

@article{Bivort2016,
  title = {Evidence for Selective Attention in the Insect Brain},
  author = {De Bivort, Benjamin L. and Van Swinderen, Bruno},
  year = {2016},
  volume = {15},
  pages = {1--7},
  issn = {22145753},
  doi = {10.1016/j.cois.2016.02.007},
  abstract = {The capacity for selective attention appears to be required by any animal responding to an environment containing multiple objects, although this has been difficult to study in smaller animals such as insects. Clear operational characteristics of attention however make study of this crucial brain function accessible to any animal model. Whereas earlier approaches have relied on freely behaving paradigms placed in an ecologically relevant context, recent tethered preparations have focused on brain imaging and electrophysiology in virtual reality environments. Insight into brain activity during attention-like behavior has revealed key elements of attention in the insect brain. Surprisingly, a variety of brain structures appear to be involved, suggesting that even in the smallest brains attention might involve widespread coordination of neural activity.},
  journal = {Current Opinion in Insect Science},
  keywords = {attention,bees,drosophila,insects},
  pmid = {27436727}
}

@article{Buatois2017,
  title = {Associative Visual Learning by Tethered Bees in a Controlled Visual Environment},
  author = {Buatois, A. and Pichot, C. and Schultheiss, P. and Sandoz, J.-C. and Lazzari, C. R. and Chittka, L. and {Avargu{\`e}s-Weber}, A. and Giurfa, M.},
  year = {2017},
  volume = {7},
  pages = {12903},
  doi = {10.1038/s41598-017-12631-w},
  abstract = {Free-flying honeybees exhibit remarkable cognitive capacities but the neural underpinnings of these capacities cannot be studied in flying insects. Conversely, immobilized bees are accessible to neurobiological investigation but display poor visual learning. To overcome this limitation, we aimed at establishing a controlled visual environment in which tethered bees walking on a spherical treadmill learn to discriminate visual stimuli video projected in front of them. Freely flying bees trained to walk into a miniature Y-maze displaying these stimuli in a dark environment learned the visual discrimination efficiently when one of them (CS+) was paired with sucrose and the other with quinine solution (CS-). Adapting this discrimination to the treadmill paradigm with a tethered, walking bee was successful as bees exhibited robust discrimination and preferred the CS+ to the CS- after training. As learning was better in the maze, movement freedom, active vision and behavioral context might be important for visual learning. The nature of the punishment associated with the CS- also affects learning as quinine and distilled water enhanced the proportion of learners. Thus, visual learning is amenable to a controlled environment in which tethered bees learn visual stimuli, a result that is important for future neurobiological studies in virtual reality.},
  journal = {Scientific Reports},
  keywords = {bees,vr},
  number = {1}
}

@article{Buatois2018,
  title = {Transfer of Visual Learning between a Virtual and a Real Environment in Honey Bees: {{The}} Role of Active Vision},
  author = {Buatois, A. and Flumian, C. and Schultheiss, P. and {Avargu{\`e}s-Weber}, A. and Giurfa, M.},
  year = {2018},
  volume = {12},
  pages = {1--17},
  doi = {10.3389/fnbeh.2018.00139},
  abstract = {To study visual learning in honey bees, we developed a virtual reality (VR) system in which the movements of a tethered bee walking stationary on a spherical treadmill update the visual panorama presented in front of it (closed-loop conditions), thus creating an experience of immersion within a virtual environment. In parallel, we developed a small Y-maze with interchangeable end-boxes, which allowed replacing repeatedly a freely walking bee into the starting point of the maze for repeated decision recording. Using conditioning and transfer experiments between the VR setup and the Y-maze, we studied the extent to which movement freedom and active vision are crucial for learning a simple color discrimination. Approximately 57\% of the bees learned the visual discrimination in both conditions. Transfer from VR to the maze improved significantly the bees' performances: 75\% of bees having chosen the CS+ continued doing so and 100\% of bees having chosen the CS- reverted their choice in favor of the CS+. In contrast, no improvement was seen for these two groups of bees during the reciprocal transfer from the Y-maze to VR. In this case, bees exhibited inconsistent choices in the VR setup. The asymmetric transfer between contexts indicates that the information learned in each environment may be different despite the similar learning success. Moreover, it shows that reducing the possibility of active vision and movement freedom in the passage from the maze to the VR impairs the expression of visual learning while increasing them in the reciprocal transfer improves it. Our results underline the active nature of visual processing in bees and allow discussing the developments required for immersive VR experiences in insects.},
  journal = {Frontiers in Behavioral Neuroscience},
  keywords = {Honey bees,Insect cognition,Transfer of learning,Virtual reality,Visual conditioning,Y-maze},
  number = {July}
}

@article{Campos2012,
  title = {Multisensory Integration in the Estimation of Walked Distances},
  author = {Campos, J. L. and Butler, J. S. and B{\"u}lthoff, H. H.},
  year = {2012},
  volume = {218},
  pages = {551--565},
  doi = {10.1007/s00221-012-3048-1},
  abstract = {When walking through space, both dynamic visual information (optic flow) and body-based information (proprioceptive and vestibular) jointly specify the magnitude of distance travelled. While recent evidence has demonstrated the extent to which each of these cues can be used independently, less is known about how they are integrated when simultaneously present. Many studies have shown that sensory information is integrated using a weighted linear sum, yet little is known about whether this holds true for the integration of visual and body-based cues for travelled distance perception. In this study using Virtual Reality technologies, participants first travelled a predefined distance and subsequently matched this distance by adjusting an egocentric, in-depth target. The visual stimulus consisted of a long hallway and was presented in stereo via a head-mounted display. Body-based cues were provided either by walking in a fully tracked free-walking space (Exp. 1) or by being passively moved in a wheelchair (Exp. 2). Travelled distances were provided either through optic flow alone, body-based cues alone or through both cues combined. In the combined condition, visually specified distances were either congruent (1.0\texttimes ) or incongruent (0.7\texttimes{} or 1.4\texttimes ) with distances specified by body-based cues. Responses reflect a consistent combined effect of both visual and body-based information, with an overall higher influence of body-based cues when walking and a higher influence of visual cues during passive movement. When comparing the results of Experiments 1 and 2, it is clear that both proprioceptive and vestibular cues contribute to travelled distance estimates during walking. These observed results were effectively described using a basic linear weighting model.},
  journal = {Experimental Brain Research},
  keywords = {Distance estimation,Multisensory integration,Optic flow,Proprioception,Self-motion,Vestibular},
  number = {4}
}

@article{Chouinard-Thuly2017,
  title = {Technical and Conceptual Considerations for Using Animated Stimuli in Studies of Animal Behavior},
  author = {{Chouinard-Thuly}, Laura and Gierszewski, Stefanie and Rosenthal, Gil G. and Reader, Simon M. and Rieucau, Guillaume and Woo, Kevin L. and Gerlai, Robert and Tedore, Cynthia and Ingley, Spencer J. and Stowers, John R. and Frommen, Joachim G. and Dolins, Francine L. and Witte, Klaudia},
  year = {2017},
  volume = {63},
  pages = {5--19},
  issn = {16745507},
  doi = {10.1093/cz/zow104},
  abstract = {Rapid technical advances in the field of computer animation (CA) and virtual reality (VR) have opened new avenues in animal behavior research. Animated stimuli are powerful tools as they offer standardization, repeatability, and complete control over the stimulus presented, thereby "reducing" and "replacing" the animals used, and "refining" the experimental design in line with the 3Rs. However, appropriate use of these technologies raises conceptual and technical questions. In this review, we offer guidelines for common technical and conceptual considerations related to the use of animated stimuli in animal behavior research. Following the steps required to create an animated stimulus, we discuss (I) the creation, (II) the presentation, and (III) the validation of CAs and VRs. Although our review is geared toward computer-graphically designed stimuli, considerations on presentation and validation also apply to video playbacks. CA and VR allow both new behavioral questions to be addressed and existing questions to be addressed in new ways, thus we expect a rich future for these methods in both ultimate and proximate studies of animal behavior.},
  journal = {Current Zoology},
  keywords = {Animal behavior,Animated stimulus,Computer animation,Experimental design,Virtual reality,Visual communication},
  number = {1}
}

@misc{Cohen2017a,
  title = {{{MouseoVeR}} : {{A Virtual Reality Software Suite}} for the {{Laboratory}}},
  author = {Cohen, J. D. and Bolstad, M. and Lee, A. K.},
  year = {2017}
}

@article{Corfas2019,
  title = {Diverse {{Food}}-{{Sensing Neurons Trigger Idiothetic Local Search}} in {{Drosophila}}},
  author = {Corfas, Rom{\'a}n A. and Sharma, Tarun and Dickinson, Michael H.},
  year = {2019},
  volume = {29},
  pages = {1660-1668.e4},
  issn = {09609822},
  doi = {10.1016/j.cub.2019.03.004},
  abstract = {Foraging animals may benefit from remembering the location of a newly discovered food patch while continuing to explore nearby [1, 2]. For example, after encountering a drop of yeast or sugar, hungry flies often perform a local search [3, 4]. That is, rather than remaining on the food or simply walking away, flies execute a series of exploratory excursions during which they repeatedly depart and return to the resource. Fruit flies, Drosophila melanogaster, can perform this food-centered search behavior in the absence of external landmarks, instead relying on internal (idiothetic) cues [5]. This path-integration behavior may represent a deeply conserved navigational capacity in insects [6, 7], but its underlying neural basis remains unknown. Here, we used optogenetic activation to screen candidate cell classes and found that local searches can be initiated by diverse sensory neurons. Optogenetically induced searches resemble those triggered by actual food, are modulated by starvation state, and exhibit key features of path integration. Flies perform tightly centered searches around the fictive food site, even within a constrained maze, and they can return to the fictive food site after long excursions. Together, these results suggest that flies enact local searches in response to a wide variety of food-associated cues and that these sensory pathways may converge upon a common neural system for navigation. Using a virtual reality system, we demonstrate that local searches can be optogenetically induced in tethered flies walking on a spherical treadmill, laying the groundwork for future studies to image the brain during path integration. Video Abstract: After finding a patch of food, flies use path integration to execute a local search. Using optogenetic activation, Corfas et al. show that a variety of food-associated neurons trigger this behavior and that flies can perform searches within a maze or a virtual environment. The results pave the way for studying the neural basis of path integration.},
  journal = {Current Biology},
  keywords = {central complex,navigation,path integration,spatial memory},
  number = {10},
  pmid = {31056390}
}

@article{Dahmen2017,
  title = {Naturalistic Path Integration of {{Cataglyphis}} Desert Ants on an Air-Cushioned Lightweight Spherical Treadmill},
  author = {Dahmen, Hansj{\"u}rgen and Wahl, Verena L. and Pfeffer, Sarah E. and Mallot, Hanspeter A. and Wittlinger, Matthias},
  year = {2017},
  month = feb,
  volume = {220},
  pages = {634--644},
  issn = {0022-0949},
  doi = {10.1242/jeb.148213},
  abstract = {Air-cushioned spheres are widely used as treadmills to study behavioural and neurophysiological questions in numerous species. We describe an improved spherical treadmill design that reliably registers the path and walking behaviour of an animal walking on top of the sphere. The simple and robust set-up consists of a very light hollowed styrofoam ball supported by an air stream in a hollow half sphere and can be used indoors and outdoors. Two optical mouse sensors provided with lenses of 4.6\hspace{0.25em}mm focal length detect the motion of the sphere with a temporal resolution of more than 200 frames s-1 and a spatial resolution of less than 0.2\hspace{0.25em}mm. The treadmill can be used in an open- or closed-loop configuration with respect to yaw of the animal. The tethering allows animals to freely adjust their body posture and in the closed-loop configuration to quickly rotate around their yaw axis with their own moment of inertia. In this account, we present the first evidence of naturalistic homing navigation on a spherical treadmill for two species of Cataglyphis desert ants. We were able to evaluate with good precision the walking speed and angular orientation at any time. During homing the ants showed a significant difference in walking speed between the approach and search phases; moreover, they slowed down significantly as soon as they reached zero vector state, the fictive nest position.},
  file = {/Users/roaldarbol/Zotero/storage/W6KNYTIJ/Dahmen et al. - 2017 - Naturalistic path integration of Cataglyphis deser.pdf;/Users/roaldarbol/Zotero/storage/QISNQVS3/Naturalistic-path-integration-of-Cataglyphis.html},
  journal = {Journal of Experimental Biology},
  keywords = {ant navigation,ants,fast response treadmill,homing,optical mouse motion,orientation behaviour,sensors,trackball},
  number = {4}
}

@article{Fry2008,
  title = {{{TrackFly}}: Virtual Reality for a Behavioral System Analysis in Free-Flying Fruit Flies.},
  author = {Fry, S. N. and Rohrseitz, N. and Straw, A. D. and Dickinson, M. H.},
  year = {2008},
  volume = {171},
  pages = {110--7},
  doi = {10.1016/j.jneumeth.2008.02.016},
  abstract = {Modern neuroscience and the interest in biomimetic control design demand increasingly sophisticated experimental techniques that can be applied in freely moving animals under realistic behavioral conditions. To explore sensorimotor flight control mechanisms in free-flying fruit flies (Drosophila melanogaster), we equipped a wind tunnel with a Virtual Reality (VR) display system based on standard digital hardware and a 3D path tracking system. We demonstrate the experimental power of this approach by example of a 'one-parameter open loop' testing paradigm. It provided (1) a straightforward measure of transient responses in presence of open loop visual stimulation; (2) high data throughput and standardized measurement conditions from process automation; and (3) simplified data analysis due to well-defined testing conditions. Being based on standard hardware and software techniques, our methods provide an affordable, easy to replicate and general solution for a broad range of behavioral applications in freely moving animals. Particular relevance for advanced behavioral research tools originates from the need to perform detailed behavioral analyses in genetically modified organisms and animal models for disease research. \textcopyright{} 2008 Elsevier B.V. All rights reserved.},
  journal = {Journal of neuroscience methods},
  number = {1},
  pmid = {18405978}
}

@article{Fry2009,
  title = {Visual Control of Flight Speed in {{Drosophila}} Melanogaster},
  author = {Fry, S. N. and Rohrseitz, N. and Straw, A. D. and Dickinson, M. H.},
  year = {2009},
  volume = {212},
  pages = {1120--1130},
  issn = {00220949},
  doi = {10.1242/jeb.020768},
  abstract = {Flight control in insects depends on self-induced image motion (optic flow), which the visual system must process to generate appropriate corrective steering maneuvers. Classic experiments in tethered insects applied rigorous system identification techniques for the analysis of turning reactions in the presence of rotating pattern stimuli delivered in open-loop. However, the functional relevance of these measurements for visual free-flight control remains equivocal due to the largely unknown effects of the highly constrained experimental conditions. To perform a systems analysis of the visual flight speed response under free-flight conditions, we implemented a 'one-parameter open-loop' paradigm using 'TrackFly' in a wind tunnel equipped with real-time tracking and virtual reality display technology. Upwind flying flies were stimulated with sine gratings of varying temporal and spatial frequencies, and the resulting speed responses were measured from the resulting flight speed reactions. To control flight speed, the visual system of the fruit fly extracts linear pattern velocity robustly over a broad range of spatio-temporal frequencies. The speed signal is used for a proportional control of flight speed within locomotor limits. The extraction of pattern velocity over a broad spatio-temporal frequency range may require more sophisticated motion processing mechanisms than those identified in flies so far. In Drosophila, the neuromotor pathways underlying flight speed control may be suitably explored by applying advanced genetic techniques, for which our data can serve as a baseline. Finally, the high-level control principles identified in the fly can be meaningfully transferred into a robotic context, such as for the robust and efficient control of autonomous flying micro air vehicles.},
  journal = {Journal of Experimental Biology},
  keywords = {Behavior,Drosophila,Flight control,Vision},
  number = {8}
}

@article{Goulard2020a,
  title = {A Motion Compensation Treadmill for Untethered Wood Ants ({{Formica}} Rufa): Evidence for Transfer of Orientation Memories from Free-Walking Training},
  shorttitle = {A Motion Compensation Treadmill for Untethered Wood Ants ({{Formica}} Rufa)},
  author = {Goulard, Roman and Buehlmann, Cornelia and Niven, Jeremy E. and Graham, Paul and Webb, Barbara},
  year = {2020},
  month = dec,
  volume = {223},
  issn = {0022-0949},
  doi = {10.1242/jeb.228601},
  abstract = {The natural scale of insect navigation during foraging makes it challenging to study under controlled conditions. Virtual reality and trackball setups have offered experimental control over visual environments while studying tethered insects, but potential limitations and confounds introduced by tethering motivates the development of alternative untethered solutions. In this paper, we validate the use of a motion compensator (or `treadmill') to study visually driven behaviour of freely moving wood ants (Formica rufa). We show how this setup allows naturalistic walking behaviour and preserves foraging motivation over long time frames. Furthermore, we show that ants are able to transfer associative and navigational memories from classical maze and arena contexts to our treadmill. Thus, we demonstrate the possibility to study navigational behaviour over ecologically relevant durations (and virtual distances) in precisely controlled environments, bridging the gap between natural and highly controlled laboratory experiments.},
  file = {/Users/roaldarbol/Dropbox/Literature/papers/Goulard2020.pdf;/Users/roaldarbol/Zotero/storage/EA2VAYY2/A-motion-compensation-treadmill-for-untethered.html;/Users/roaldarbol/Zotero/storage/YI4E8WAZ/A-motion-compensation-treadmill-for-untethered.html},
  journal = {Journal of Experimental Biology},
  number = {24}
}

@article{Haberkern2019,
  title = {Visually {{Guided Behavior}} and {{Optogenetically Induced Learning}} in {{Head}}-{{Fixed Flies Exploring}} a {{Virtual Landscape}}},
  author = {Haberkern, Hannah and Basnak, Melanie A. and Ahanonu, Biafra and Schauder, David and Cohen, Jeremy D. and Bolstad, Mark and Bruns, Christopher and Jayaraman, Vivek},
  year = {2019},
  volume = {29},
  pages = {1--13},
  publisher = {{Elsevier Ltd.}},
  issn = {09609822},
  doi = {10.1016/j.cub.2019.04.033},
  abstract = {Studying the intertwined roles of sensation, experience, and directed action in navigation has been facilitated by the development of virtual reality (VR) environments for head-fixed animals, allowing for quantitative measurements of behavior in well-controlled conditions. VR has long featured in studies of Drosophila melanogaster, but these experiments have typically allowed the fly to change only its heading in a visual scene and not its position. Here we explore how flies move in two dimensions (2D) using a visual VR environment that more closely captures an animal's experience during free behavior. We show that flies' 2D interaction with landmarks cannot be automatically derived from their orienting behavior under simpler one-dimensional (1D) conditions. Using novel paradigms, we then demonstrate that flies in 2D VR adapt their behavior in response to optogenetically delivered appetitive and aversive stimuli. Much like free-walking flies after encounters with food, head-fixed flies exploring a 2D VR respond to optogenetic activation of sugar-sensing neurons by initiating a local search, which appears not to rely on visual landmarks. Visual landmarks can, however, help flies to avoid areas in VR where they experience an aversive, optogenetically generated heat stimulus. By coupling aversive virtual heat to the flies' presence near visual landmarks of specific shapes, we elicit selective learned avoidance of those landmarks. Thus, we demonstrate that head-fixed flies adaptively navigate in 2D virtual environments, but their reliance on visual landmarks is context dependent. These behavioral paradigms set the stage for interrogation of the fly brain circuitry underlying flexible navigation in complex multisensory environments. Haberkern et al. explore the role of visual landmarks in guiding navigation of head-fixed walking Drosophila melanogaster using a 2D virtual reality system. The degree to which flies rely on visual landmarks depends on environmental and behavioral context, which can be created by optogenetic activation of appropriate sensory pathways.},
  journal = {Current Biology},
  keywords = {Drosophila melanogaster,navigation,operant learning,optogenetics,search,virtual reality,visual conditioning},
  number = {10},
  pmid = {31056392}
}

@article{Hobson2009,
  title = {{{REM}} Sleep and Dreaming: {{Towards}} a Theory of Protoconsciousness},
  author = {Hobson, J. Allan},
  year = {2009},
  volume = {10},
  pages = {803--814},
  publisher = {{Nature Publishing Group}},
  issn = {1471003X},
  doi = {10.1038/nrn2716},
  abstract = {Dreaming has fascinated and mystified humankind for ages: the bizarre and evanescent qualities of dreams have invited boundless speculation about their origin, meaning and purpose. For most of the twentieth century, scientific dream theories were mainly psychological. Since the discovery of rapid eye movement (REM) sleep, the neural underpinnings of dreaming have become increasingly well understood, and it is now possible to complement the details of these brain mechanisms with a theory of consciousness that is derived from the study of dreaming. The theory advanced here emphasizes data that suggest that REM sleep may constitute a protoconscious state, providing a virtual reality model of the world that is of functional use to the development and maintenance of waking consciousness. \textcopyright{} 2009 Macmillan Publishers Limited. All rights reserved.},
  journal = {Nature Reviews Neuroscience},
  number = {11},
  pmid = {19794431}
}

@phdthesis{Hofbauer2015,
  title = {Colour {{Vision}} in {{Cupiennius}} Salei - a {{Behavioural Approach}} with {{Virtual Reality}}},
  author = {Hofbauer, M.},
  year = {2015}
}

@article{Holscher2005,
  title = {Rats Are Able to Navigate in Virtual Environments},
  author = {H{\"o}lscher, C. and Schnee, A. and Dahmen, H. and Setia, L. and Mallot, H. A.},
  year = {2005},
  volume = {208},
  pages = {561--569},
  issn = {00220949},
  doi = {10.1242/jeb.01371},
  abstract = {Virtual reality (VR) systems are useful tools that enable users to alter environmental settings and the location of landmarks in an accurate and fast way. Primates have been shown to be able to navigate in virtual environments. For rodents, however, all previous attempts to develop VR systems in which rats behave in the same way as in corresponding 3-D environments have failed. The question arises as to whether, in principle, rodents can be trained to navigate in a properly designed virtual environment (VE), or whether this peculiarity is limited to primates and humans. We built a virtual reality set-up that takes the wide-angle visual system of rats into account. We show for the first time that rats learn spatial tasks in this VE quite readily. This set-up opens up new opportunities for investigations of information processing in navigation (e.g. the importance of optic flow or vestibular input).},
  journal = {Journal of Experimental Biology},
  keywords = {Learning,Memory,Rat,Spatial,Virtual reality},
  number = {3}
}

@article{Kaupert2017,
  title = {Spatial Cognition in a Virtual Reality Home-Cage Extension for Freely Moving Rodents},
  author = {Kaupert, Ursula and Thurley, Kay and Frei, Katja and Bagorda, Francesco and Schatz, Alexej and Tocker, Gilad and Rapoport, Sophie and Derdikman, Dori and Winter, York},
  year = {2017},
  volume = {117},
  pages = {1736--1748},
  issn = {15221598},
  doi = {10.1152/jn.00630.2016},
  abstract = {Virtual reality (VR) environments are a powerful tool to investigate brain mechanisms involved in the behavior of animals. With this technique, animals are usually head fixed or secured in a harness, and training for cognitively more complex VR paradigms is time consuming. A VR apparatus allowing free animal movement and the constant operator-independent training of tasks would enable many new applications. Key prospective usages include brain imaging of animal behavior when carrying a miniaturized mobile device such as a fluorescence microscope or an optetrode. Here, we introduce the Servoball, a spherical VR treadmill based on the closed-loop tracking of a freely moving animal and feedback counterrotation of the ball. Furthermore, we present the complete integration of this experimental system with the animals' group home cage, from which single individuals can voluntarily enter through a tunnel with radio-frequency identification (RFID)-automated access control and commence experiments. This automated animal sorter functions as a mechanical replacement of the experimenter. We automatically trained rats using visual or acoustic cues to solve spatial cognitive tasks and recorded spatially modulated entorhinal cells. When electrophysiological extracellular recordings from awake behaving rats were performed, head fixation can dramatically alter results, so that any complex behavior that requires head movement is impossible to achieve. We circumvented this problem with the use of the Servoball in open-field scenarios, as it allows the combination of open-field behavior with the recording of nerve cells, along with all the flexibility that a virtual environment brings. This integrated home cage with a VR arena experimental system permits highly efficient experimentation for complex cognitive experiments.},
  journal = {Journal of Neurophysiology},
  keywords = {24/7,Freely moving,Operator independent,Spatial cognition,Virtual reality},
  number = {4},
  pmid = {28077665}
}

@article{Kautzky2016,
  title = {Estimation of Self-Motion Duration and Distance in Rodents},
  author = {Kautzky, Magdalena and Thurley, Kay},
  year = {2016},
  volume = {3},
  issn = {20545703},
  doi = {10.1098/rsos.160118},
  abstract = {\textcopyright{} 2016 The Authors. Spatial orientation and navigation rely on information about landmarks and self-motion cues gained from multi-sensory sources. In this study, we focused on self-motion and examined the capability of rodents to extract and make use of information about own movement, i.e. path integration. Path integration has been investigated in depth in insects and humans. Demonstrations in rodents, however, mostly stem from experiments on heading direction; less is known about distance estimation. We introduce a novel behavioural paradigm that allows for probing temporal and spatial contributions to path integration. The paradigm is a bisection task comprising movement in a virtual reality environment in combination with either timing the duration ran or estimating the distance covered. We performed experiments with Mongolian gerbils and could show that the animals can keep track of time and distance during spatial navigation.},
  journal = {Royal Society Open Science},
  keywords = {Bisection task,Interval timing,Odometry,Path integration,Rodent navigation,Virtual reality},
  number = {5}
}

@article{Kislin2014,
  title = {Flat-Floored {{Air}}-Lifted {{Platform}}: {{A New Method}} for {{Combining Behavior}} with {{Microscopy}} or {{Electrophysiology}} on {{Awake Freely Moving Rodents}}},
  author = {Kislin, M. and Mugantseva, E. and Molotkov, D. and Kulesskaya, N. and Khirug, S. and Kirilkin, I. and Pryazhnikov, E. and Kolikova, J. and Toptunov, D. and Yuryev, M. and Giniatullin, R. and Voikar, V. and Rivera, C. and Rauvala, H. and Khiroug, L.},
  year = {2014},
  pages = {1--11},
  doi = {10.3791/51869},
  abstract = {It is widely acknowledged that the use of general anesthetics can undermine the relevance of electrophysiological or microscopical data obtained from a living animal's brain. Moreover, the lengthy recovery from anesthesia limits the frequency of repeated recording/imaging episodes in longitudinal studies. Hence, new methods that would allow stable recordings from non-anesthetized behaving mice are expected to advance the fields of cellular and cognitive neurosciences. Existing solutions range from mere physical restraint to more sophisticated approaches, such as linear and spherical treadmills used in combination with computer-generated virtual reality. Here, a novel method is described where a head-fixed mouse can move around an air-lifted mobile homecage and explore its environment under stress-free conditions. This method allows researchers to perform behavioral tests (e.g., learning, habituation or novel object recognition) simultaneously with two-photon microscopic imaging and/or patch-clamp recordings, all combined in a single experiment. This video-article describes the use of the awake animal head fixation device (mobile homecage), demonstrates the procedures of animal habituation, and exemplifies a number of possible applications of the method.},
  journal = {Journal of Visualized Experiments},
  keywords = {awake,blood vessels,ca,dendrites,dendritic spines,in vivo two-photon microscopy,issue 88},
  number = {88}
}

@article{Lopes2020,
  title = {{{BonVision}} \textendash{} an Open-Source Software to Create and Control Visual Environments},
  author = {Lopes, Gon{\c c}alo and Farrell, Karolina and Horrocks, Edward and Lee, Chi-Yu and Morimoto, Mai and Muzzu, Tomaso and Papanikolaou, Amalia and Rodrigues, Fabio and Wheatcroft, Thomas and Zucca, Stefano and Solomon, Samuel and Saleem, Aman},
  year = {2020},
  pages = {1--17},
  doi = {10.1101/2020.03.09.983775},
  abstract = {Real-time rendering of closed-loop visual environments is necessary for next-generation understanding of brain function and behaviour, but is prohibitively difficult for non-experts to implement and is limited to few laboratories worldwide. We developed BonVision as an easy-to-use software for display of virtual or augmented reality as well as standard visual stimuli. As the architecture is based on the open-source Bonsai graphical programming language, BonVision benefits from Bonsai's native integration with experimental hardware. BonVision therefore enables easy implementation of closed-loop experiments and communication with behavioural and physiological measurement and manipulation devices, while being open-source, easy to install, and able to run on standard personal computers.}
}

@article{Masterarbeit2015,
  title = {Masterarbeit {{Colour Vision}} in {{Cupiennius}} Salei - a {{Behavioural Approach}} with {{Virtual Reality Maximilian Hofbauer}} , {{BSc Master}} of {{Science}} ( {{MSc}} )},
  author = {Masterarbeit, Titel Der},
  year = {2015}
}

@article{Miall1978,
  title = {The Flicker Fusion Frequencies of Six Laboratory Insects, and the Response of the Compound Eye to Mains Fluorescent `Ripple'},
  author = {Miall, R. C.},
  year = {1978},
  volume = {3},
  pages = {99--106},
  issn = {1365-3032},
  doi = {10.1111/j.1365-3032.1978.tb00139.x},
  abstract = {ABSTRACT. The ERG response of the compound eye to single, brief, light pulses, to sustained stimulation for 2 s, and the dark adapted flicker-fusion frequency (FFF) under stroboscopic light was measured in six species: Locusta migratoria (FFF range: 40\textendash 90 Hz), Periplaneta americana (25\textendash 60 Hz), Saturnia pavonia (65\textendash 85 Hz), Antheraea pernyi (25\textendash 70 Hz), Glossina morsitans (85\textendash 205 Hz) and Drosophila hydei (60\textendash 100 Hz). The first four species have typical `slow-eyed', monophasic ERG responses; the two flies typical `fast-eyed', biphasic responses. The FFF proved to be dependent on the state of light adaptation, being 40\textendash 70\% higher than the above figures after only 2 min exposure to as little as 300 lx. Adult male Glossina, but not Locusta nymphs, showed a clear 100 Hz ERG ripple in response to single-phase, mains fluorescent lighting. To three-phase fluorescent lighting no 300 Hz ERG ripple was detected, but the 100 Hz component was still evident.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-3032.1978.tb00139.x},
  file = {/Users/roaldarbol/Zotero/storage/SRFE74XM/j.1365-3032.1978.tb00139.html},
  journal = {Physiological Entomology},
  language = {en},
  number = {2}
}

@article{Nashaat2016,
  title = {Air-{{Track}}: {{A}} Real-World Floating Environment for Active Sensing in Head-Fixed Mice},
  author = {Nashaat, Mostafa A. and Oraby, Hatem and Sachdev, Robert N.S. and Winter, York and Larkum, Matthew E.},
  year = {2016},
  volume = {116},
  pages = {1542--1553},
  issn = {15221598},
  doi = {10.1152/jn.00088.2016},
  abstract = {Natural behavior occurs in multiple sensory and motor modalities and in particular is dependent on sensory feedback that constantly adjusts behavior. To investigate the underlying neuronal correlates of natural behavior, it is useful to have access to state-of-the-art recording equipment (e.g., 2-photon imaging, patch recordings, etc.) that frequently requires head fixation. This limitation has been addressed with various approaches such as virtual reality/air ball or treadmill systems. However, achieving multimodal realistic behavior in these systems can be challenging. These systems are often also complex and expensive to implement. Here we present ``Air-Track,'' an easy-to-build head-fixed behavioral environment that requires only minimal computational processing. The Air-Track is a lightweight physical maze floating on an air table that has all the properties of the ``real'' world, including multiple sensory modalities tightly coupled to motor actions. To test this system, we trained mice in Go/No-Go and two-alternative forced choice tasks in a plus maze. Mice chose lanes and discriminated apertures or textures by moving the Air-Track back and forth and rotating it around themselves. Mice rapidly adapted to moving the track and used visual, auditory, and tactile cues to guide them in performing the tasks. A custom-controlled camera system monitored animal location and generated data that could be used to calculate reaction times in the visual and somatosensory discrimination tasks. We conclude that the Air-Track system is ideal for eliciting natural behavior in concert with virtually any system for monitoring or manipulating brain activity.},
  journal = {Journal of Neurophysiology},
  keywords = {Head-fixed behavior,Multisensory perception,Psychophysics,Virtual reality},
  number = {4},
  pmid = {27486102}
}

@article{NicholasAndrewDelGrosso2018,
  title = {Design of Virtual Reality Systems for Animal Behavior Research},
  author = {{Nicholas Andrew Del Grosso}},
  year = {2018},
  volume = {August},
  abstract = {Virtual reality (VR) experimental behavior setups enable cognitive neuroscientists to study the integration of visual depth cues and self-motion cues into a single per- cept of three-dimensional space. Rodents can navigate a virtual environment by running on a spherical treadmill, but simulating locomotion in this way can both bias and suppress the frequency of their behaviors as well as introduce vestibulo- motor and vestibulovisual sensory conflict during locomotion. Updating the vir- tual environment via the subject's own freely-moving head movements solves both the naturalistic behavior bias and vestibular conflict issues. In this thesis, I review elements of self-motion and 3D scene perception that contribute to a sense of im- mersion in virtual environments and suggest a freely-moving CAVE system as a VR solution for low-artifact neuroscience experiments. The manuscripts describing the 3D graphics Python package and the virtual reality setup are included. In this freely- moving CAVE VR setup, freely-moving rats demonstrate immersion in virtual en- vironments by displaying height aversion to virtual cliffs, exploration preference of virtual objects, and spontaneously modify their locomotion trajectories near virtual walls. These experiments help bridge the classic behavior and virtual reality litera- ture by showing that rats display similar behaviors to virtual environment features without training.},
  journal = {Dissertation der Graduate School of Systemic Neurosciences der Ludwig-Maximillians-Universit\"at M\"unchen},
  keywords = {Behavior,CAVE,Spatial Perception,Virtual Reality}
}

@article{Paulk2015,
  title = {Closed-{{Loop Behavioral Control Increases Coherence}} in the {{Fly Brain}}},
  author = {Paulk, A. C. and Kirszenblat, L. and Zhou, Y. and {van Swinderen}, B.},
  year = {2015},
  volume = {35},
  pages = {10304--10315},
  issn = {0270-6474},
  doi = {10.1523/jneurosci.0691-15.2015},
  abstract = {UNLABELLED: A crucial function of the brain is to be able to distinguish whether or not changes in the environment are caused by one's own actions. Even the smallest brains appear to be capable of making this distinction, as has been shown by closed-loop behavioral experiments in flies controlling visual stimuli in virtual reality paradigms. We questioned whether activity in the fruit fly brain is different during such closed-loop behavior, compared with passive viewing of a stimulus. To address this question, we used a procedure to record local field potential (LFP) activity across the fly brain while flies were controlling a virtual object through their movement on an air-supported ball. The virtual object was flickered at a precise frequency (7 Hz), creating a frequency tag that allowed us to track brain responses to the object while animals were behaving. Following experiments under closed-loop control, we replayed the same stimulus to the fly in open loop, such that it could no longer control the stimulus. We found identical receptive fields and similar strength of frequency tags across the brain for the virtual object under closed loop and replay. However, when comparing central versus peripheral brain regions, we found that brain responses were differentially modulated depending on whether flies were in control or not. Additionally, coherence of LFP activity in the brain increased when flies were in control, compared with replay, even if motor behavior was similar. This suggests that processes associated with closed-loop control promote temporal coordination in the insect brain. SIGNIFICANCE STATEMENT: We show that closed-loop control of a visual stimulus promotes temporal coordination across the Drosophila brain, compared with open-loop replay of the same visual sequences. This is significant because it suggests that, to understand goal-directed behavior or visual attention in flies, it may be most informative to sample neural activity from multiple regions across the brain simultaneously, and to examine temporal relationships (e.g., coherence) between these regions.},
  journal = {Journal of Neuroscience},
  keywords = {across the drosophila brain,behavior,closed-loop,compared,control of a visual,drosophila,electrophysiology,it suggests that,significance statement,ssvep,stimulus promotes temporal coordination,the same visual sequences,this is significant because,to understand goal-directed,vision,we show that closed-loop,with open-loop replay of},
  number = {28}
}

@article{Peckmezian2015a,
  title = {A Virtual Reality Paradigm for the Study of Visually Mediated Behaviour and Cognition in Spiders},
  author = {Peckmezian, Tina and Taylor, Phillip W.},
  year = {2015},
  volume = {107},
  pages = {87--95},
  publisher = {{Elsevier Ltd}},
  issn = {0003-3472},
  doi = {10.1016/j.anbehav.2015.06.018},
  abstract = {Jumping spiders (Salticidae) are well known for their unique, high-acuity visual system and complex, visually mediated behaviour. To overcome the limitations of video playback and other open loop systems that are currently available for the study of visually mediated behaviour in jumping spiders, we developed a closed-loop, virtual reality (VR) system in which a spider on a spherical treadmill walks through a projected 3D world that updates in real time in response to its movements. To investigate VR as an experimental technique for spiders as well as validate it as a proxy of the real world, we conducted two experiments to assess whether individual behavioural tendencies and learning transferred from real to virtual environments. In the first experiment, we examined transference of individual behaviour tendencies (spontaneous locomotion and dark/light preference) between real and VR environments, and found that individual differences were conserved. In the second experiment, we investigated transference of beacon-learning tasks between real and VR environments. We found that spiders that had learned a beacon-nest site association in the real world tended to expresses similar associations in the virtual world. Virtual reality offers great promise as a new tool to explore the cognitive processes underlying vision-mediated learning, memory and navigation in jumping spiders. \textbullet We created an immersive virtual reality system for jumping spiders.},
  journal = {Animal Behaviour},
  keywords = {jumping spider,Jumping spider,learning,Learning,Salticidae,spiders,virtual reality,Virtual reality,vision,Vision,vr}
}

@article{Pfeffer2016,
  title = {Optic Flow Odometry Operates Independently of Stride Integration in Carried Ants},
  author = {Pfeffer, Sarah E. and Wittlinger, Matthias},
  year = {2016},
  volume = {353},
  pages = {1155--1157},
  issn = {10959203},
  doi = {10.1126/science.aaf9754},
  abstract = {applicability for this approach.},
  journal = {Science},
  number = {6304},
  pmid = {27609893}
}

@phdthesis{Roald-Arbol2021,
  title = {Does {{Optic Flow Affect Walking Behaviour}} in {{Wood Ants}}?},
  author = {{Roald-Arb{\o}l}, Mikkel},
  year = {2021},
  month = sep,
  abstract = {Optic flow, the measure of the speed at which visual input moves past the eye, is a general feature of biological vision. As the performance of the visual system is thought to affect behaviour, we set out to investigate whether self-induced optic flow affects walking behaviour of the wood ant (Formica rufa). Previous investigations of the use of optic flow in walking insects have been performed using freely moving animals, which does not permit full control of the visual experience. To overcome this we developed a novel virtual reality setup, which we validated by testing whether wood ants interact with a black beacon in virtual reality. We found that wood ants preferentially faced the beacon and exhibited aggression towards it. We take this to provide convincing evidence that wood ants interact with and utilise visual information within a virtual reality setup. To study if and how wood ants use self-generated optic flow to control walking behaviour they were placed in a completely white environment with a black pattern on the floor. We show that wood ants respond to decreased gain (x0.3) of self-induced translational optic flow by increasing their walking speed by 29-98\% and increasing their translational walking duration by 34-118\%, whereas neither normal or increased (3x) gain has any effects. We further show that the increased walking duration results both from increasing duration of walking bouts and decreasing duration of pauses. This is the first evidence that wood ants use self-induced optic flow, and the first direct evidence that the sensory experience affects locomotion duration and intermittency in any animal.},
  file = {/Users/roaldarbol/Zotero/storage/MKGK2HVH/Roald-Arb√∏l - .pdf},
  school = {University of Copenhagen}
}

@article{Schwarz2011,
  title = {The Properties of the Visual System in the {{Australian}} Desert Ant {{Melophorus}} Bagoti},
  author = {Schwarz, Sebastian and Narendra, Ajay and Zeil, Jochen},
  year = {2011},
  volume = {40},
  pages = {128--134},
  publisher = {{Elsevier Ltd}},
  issn = {14678039},
  doi = {10.1016/j.asd.2010.10.003},
  abstract = {The Australian desert ant Melophorus bagoti shows remarkable visual navigational skills relying on visual rather than on chemical cues during their foraging trips. M. bagoti ants travel individually through a visually cluttered environment guided by landmarks as well as by path integration. An examination of their visual system is hence of special interest and we address this here. Workers exhibit distinct size polymorphism and their eye and ocelli size increases with head size. The ants possess typical apposition eyes with about 420-590 ommatidia per eye, a horizontal visual field of approximately 150\textdegree{} and facet lens diameters between 8 and 19 {$\mu$}m, depending on body size, with frontal facets being largest. The average interommatidial angle {$\Delta\varphi$} is 3.7\textdegree, the average acceptance angle of the rhabdom {$\Delta\rho$}rh is 2.9\textdegree, with average rhabdom diameter of 1.6 {$\mu$}m and the average lens blur at half-width {$\Delta\rho$}l is 2.3\textdegree. With a {$\Delta\rho$}rh/{$\Delta\varphi$} ratio of much less than 2, the eyes undersample the visual scene but provide high contrast, and surprising detail of the landmark panorama that has been shown to be used for navigation. \textcopyright{} 2010 Elsevier Ltd.},
  journal = {Arthropod Structure and Development},
  keywords = {Compound eye,Insect vision,Melophorus bagoti,Ommatidia,Resolution,Visual field},
  number = {2},
  pmid = {21044895}
}

@article{Seelig2015,
  title = {Neural Dynamics for Landmark Orientation and Angular Path Integration},
  author = {Seelig, Johannes D. and Jayaraman, Vivek},
  year = {2015},
  month = may,
  volume = {521},
  pages = {186},
  publisher = {{Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.}},
  doi = {10.1038/nature14446},
  abstract = {Many animals navigate using a combination of visual landmarks and path integration. In mammalian brains, head direction cells integrate these two streams of information by representing an animal's heading relative to landmarks, yet maintaining their directional tuning in darkness based on self-motion cues. Here we use two-photon calcium imaging in head-fixed Drosophila melanogaster walking on a ball in a virtual reality arena to demonstrate that landmark-based orientation and angular path integration are combined in the population responses of neurons whose dendrites tile the ellipsoid body, a toroidal structure in the centre of the fly brain. The neural population encodes the fly's azimuth relative to its environment, tracking visual landmarks when available and relying on self-motion cues in darkness. When both visual and self-motion cues are absent, a representation of the animal's orientation is maintained in this network through persistent activity, a potential substrate for short-term memory. Several features of the population dynamics of these neurons and their circular anatomical arrangement are suggestive of ring attractors, network structures that have been proposed to support the function of navigational brain circuits.},
  journal = {Nature},
  keywords = {calcium imaging,drosophila,navigation},
  number = {7551}
}

@article{Stowers2014a,
  title = {Reverse {{Engineering Animal Vision}} with {{Virtual Reality}} and {{Genetics}}},
  author = {Stowers, John R. and Fuhrmann, Anton and Hofbauer, Maximilian and Streinzer, Martin and Schmid, Axel and Dickinson, Michael H. and Straw, Andrew D.},
  year = {2014},
  doi = {10.1109/MC.2014.190},
  abstract = {Neuroscientists are using virtual reality systems, combined with other advances such as new molecular genetic tools and brain-recording technologies, to reveal how neuronal circuits process and act on visual information.},
  journal = {Computer},
  keywords = {animal behavior,augmented reality,FlyVR,human-computer interaction,multimedia information systems,neuroscience,virtual reality,visualization}
}

@article{Takalo2012,
  title = {A Fast and Flexible Panoramic Virtual Reality System for Behavioural and Electrophysiological Experiments},
  author = {Takalo, Jouni and Piironen, Arto and Honkanen, Anna and Lempe{\"a}, Mikko and Aikio, Mika and Tuukkanen, Tuomas and V{\"a}h{\"a}s{\"o}yrinki, Mikko and Lempea, Mikko and Aikio, Mika and Tuukkanen, Tuomas and V{\"a}h{\"a}s{\"o}yrinki, Mikko and Lempe{\"a}, Mikko and Aikio, Mika and Tuukkanen, Tuomas and V{\"a}h{\"a}s{\"o}yrinki, Mikko},
  year = {2012},
  month = mar,
  volume = {2},
  pages = {324},
  publisher = {{The Author(s)}},
  issn = {20452322},
  doi = {10.1038/srep00324},
  abstract = {Ideally, neuronal functions would be studied by performing experiments with unconstrained animals whilst they behave in their natural environment. Although this is not feasible currently for most animal models, one can mimic the natural environment in the laboratory by using a virtual reality (VR) environment. Here we present a novel VR system based upon a spherical projection of computer generated images using a modified commercial data projector with an add-on fish-eye lens. This system provides equidistant visual stimulation with extensive coverage of the visual field, high spatio-temporal resolution and flexible stimulus generation using a standard computer. It also includes a track-ball system for closed-loop behavioural experiments with walking animals. We present a detailed description of the system and characterize it thoroughly. Finally, we demonstrate the VR system's performance whilst operating in closed-loop conditions by showing the movement trajectories of the cockroaches during exploratory behaviour in a VR forest.},
  journal = {Scientific Reports},
  keywords = {cockroach,vr}
}

@article{taylorInsectsModifyTheir2015,
  title = {Insects Modify Their Behaviour Depending on the Feedback Sensor Used When Walking on a Trackball in Virtual Reality},
  author = {Taylor, Gavin J. and Paulk, Angelique C. and Pearson, Thomas W. J. and Moore, Richard J. D. and Stacey, Jacqui A. and Ball, David and {van Swinderen}, Bruno and Srinivasan, Mandyam V.},
  year = {2015},
  month = oct,
  volume = {218},
  pages = {3118--3127},
  issn = {0022-0949},
  doi = {10.1242/jeb.125617},
  abstract = {When using virtual-reality paradigms to study animal behaviour, careful attention must be paid to how the animal's actions are detected. This is particularly relevant in closed-loop experiments where the animal interacts with a stimulus. Many different sensor types have been used to measure aspects of behaviour, and although some sensors may be more accurate than others, few studies have examined whether, and how, such differences affect an animal's behaviour in a closed-loop experiment. To investigate this issue, we conducted experiments with tethered honeybees walking on an air-supported trackball and fixating a visual object in closed-loop. Bees walked faster and along straighter paths when the motion of the trackball was measured in the classical fashion \textendash{} using optical motion sensors repurposed from computer mice \textendash{} than when measured more accurately using a computer vision algorithm called `FicTrac'. When computer mouse sensors were used to measure bees' behaviour, the bees modified their behaviour and achieved improved control of the stimulus. This behavioural change appears to be a response to a systematic error in the computer mouse sensor that reduces the sensitivity of this sensor system under certain conditions. Although the large perceived inertia and mass of the trackball relative to the honeybee is a limitation of tethered walking paradigms, observing differences depending on the sensor system used to measure bee behaviour was not expected. This study suggests that bees are capable of fine-tuning their motor control to improve the outcome of the task they are performing. Further, our findings show that caution is required when designing virtual-reality experiments, as animals can potentially respond to the artificial scenario in unexpected and unintended ways.},
  file = {/Users/roaldarbol/Zotero/storage/RWK4TMCI/Taylor et al. - 2015 - Insects modify their behaviour depending on the fe.pdf;/Users/roaldarbol/Zotero/storage/WUMCI7AH/Insects-modify-their-behaviour-depending-on-the.html},
  journal = {Journal of Experimental Biology},
  keywords = {adaptive control,closed-loop,computer mouse sensor,fictrac,free-walking,honeybee,sensor accuracy,tethered-walking,visual fixation},
  number = {19}
}

@article{Thurley2017,
  title = {Virtual Reality Systems for Rodents},
  author = {Thurley, Kay and Ayaz, Asli},
  year = {2017},
  volume = {63},
  pages = {109--119},
  issn = {16745507},
  doi = {10.1093/cz/zow070},
  abstract = {Over the last decade virtual reality (VR) setups for rodents have been developed and utilized to in- vestigate the neural foundations of behavior. Such VR systems became very popular since they allow the use of state-of-the-art techniques to measure neural activity in behaving rodents that can- not be easily used with classical behavior setups. Here, we provide an overview of rodent VR tech- nologies and review recent results from related research. We discuss commonalities and differ- ences as well as merits and issues of different approaches. A special focus is given to experimental (behavioral) paradigms in use. Finally we comment on possible use cases that may further exploit the potential of VR in rodent research and hence inspire future studies.},
  journal = {Current Zoology},
  keywords = {Behavioral neuroscience,Closed loop,Multisensory stimulation,Neural coding,Sensorimotor integration,Spatial navigation},
  number = {1}
}

@article{Vishniakou2019,
  title = {Virtual Reality for Animal Navigation with Camera-Based Optical Flow Tracking},
  author = {Vishniakou, Ivan and Pl{\"o}ger, Paul G. and Seelig, Johannes D.},
  year = {2019},
  volume = {327},
  pages = {108403},
  publisher = {{Elsevier}},
  issn = {1872678X},
  doi = {10.1016/j.jneumeth.2019.108403},
  abstract = {Background: Virtual reality combined with a spherical treadmill is used across species for studying neural circuits underlying navigation and learning. New method: We developed an optical flow-based method for tracking treadmill ball motion in real time using a single high-resolution camera. Results: Tracking accuracy and timing were determined using calibration data. Ball tracking was performed at 500 Hz and integrated with an open source game engine for virtual reality projection. The projection was updated at 120 Hz with a latency with respect to ball motion of 30 {$\pm$} 8 ms. The system was tested for behavior with fruit flies. The application and source code are available at https://github.com/ivan-vishniakou/neural-circuits-vr. Comparison with existing method(s): Optical flow-based tracking of treadmill motion is typically achieved using optical mice. The camera-based optical flow tracking system developed here is based on off-the-shelf components and offers control over the image acquisition and processing parameters. This results in flexibility with respect to tracking conditions \textendash{} such as ball surface texture, lighting conditions, or ball size \textendash{} as well as camera alignment and calibration. Conclusions: A fast system for rotational ball motion tracking suitable for virtual reality behavior with fruit flies was developed and characterized.},
  journal = {Journal of Neuroscience Methods},
  keywords = {Ball tracking,Drosophila,Navigation,Optical flow,Real-time image processing,Spherical treadmill,Virtual reality},
  number = {August},
  pmid = {31449825}
}

@article{Wahl2015,
  title = {Walking and Running in the Desert Ant {{Cataglyphis}} Fortis},
  author = {Wahl, V. L. and Pfeffer, S. E. and Wittlinger, M.},
  year = {2015},
  volume = {201},
  pages = {645--656},
  publisher = {{Springer Berlin Heidelberg}},
  doi = {10.1007/s00359-015-0999-2},
  abstract = {Path integration, although inherently error-prone, is a common navigation strategy in animals, particularly where environmental orientation cues are rare. The desert ant Cataglyphis fortis is a prominent example, covering large distances on foraging excursions. The stride integrator is probably the major source of path integration errors. A detailed analysis of walking behaviour in Cataglyphis is thus of importance for assessing possible sources of errors and potential compensation strategies. Zollikofer (J Exp Biol 192:95-106, 1994a) demonstrated consistent use of the tripod gait in Cataglyphis, and suggested an unexpectedly constant stride length as a possible means of reducing navigation errors. Here, we extend these studies by more detailed analyses of walking behaviour across a large range of walking speeds. Stride length increases linearly and stride amplitude of the middle legs increases slightly linearly with walking speed. An initial decrease of swing phase duration is observed at lower velocities with increasing walking speed. Then it stays constant across the behaviourally relevant range of walking speeds. Walking speed is increased by shortening of the stance phase and of the stance phase overlap. At speeds larger than 370 mms(-1), the stride frequency levels off, the duty factor falls below 0.5, and Cataglyphis transitions to running with aerial phases.},
  journal = {Journal of Comparative Physiology A: Neuroethology, Sensory, Neural, and Behavioral Physiology},
  keywords = {Cataglyphis,Desert ant,Gait,Inter-leg coordination,Stepping pattern},
  number = {6}
}

@article{Wittlinger2006,
  title = {The Ant Odometer: {{Stepping}} on Stilts and Stumps},
  author = {Wittlinger, Matthias and Wehner, R{\"u}diger and Wolf, Harald},
  year = {2006},
  volume = {312},
  pages = {1965--1967},
  issn = {00368075},
  doi = {10.1126/science.1126912},
  abstract = {Desert ants, Cataglyphis, navigate in their vast desert habitat by path integration. They continuously integrate directions steered (as determined by their celestial compass) and distances traveled, gauged by as-yet-unknown mechanisms. Here we test the hypothesis that navigating ants measure distances traveled by using some kind of step integrator, or "step counter." We manipulated the lengths of the legs and, hence, the stride lengths, in freely walking ants. Animals with elongated ("stilts") or shortened legs ("stumps") take larger or shorter strides, respectively, and concomitantly misgauge travel distance. Travel distance is overestimated by experimental animals walking on stilts and underestimated by animals walking on stumps.},
  journal = {Science},
  number = {5782},
  pmid = {16809544}
}

@article{Wittlinger2007a,
  title = {The Desert Ant Odometer: A Stride Integrator That Accounts for Stride Length and Walking Speed},
  author = {Wittlinger, Matthias and Wehner, R{\"u}diger and Wolf, Harald},
  year = {2007},
  volume = {210},
  pages = {198--207},
  issn = {0022-0949},
  doi = {10.1242/jeb.02657},
  abstract = {Desert ants, Cataglyphis, use path integration as a major means of navigation. Path integration requires measurement of two parameters, namely, direction and distance of travel. Directional information is provided by a celestial compass, whereas distance measurement is accomplished by a stride integrator, or pedometer. Here we examine the recently demonstrated pedometer function in more detail. By manipulating leg lengths in foraging desert ants we could also change their stride lengths. Ants with elongated legs ('stilts') or shortened legs ('stumps') take larger or shorter strides, respectively, and misgauge travel distance. Travel distance is overestimated by experimental animals walking on stilts, and underestimated by animals walking on stumps - strongly indicative of stride integrator function in distance measurement. High-speed video analysis was used to examine the actual changes in stride length, stride frequency and walking speed caused by the manipulations of leg length. Unexpectedly, quantitative characteristics of walking behaviour remained almost unaffected by imposed changes in leg length, demonstrating remarkable robustness of leg coordination and walking performance. These data further allowed normalisation of homing distances displayed by manipulated animals with regard to scaling and speed effects. The predicted changes in homing distance are in quantitative agreement with the experimental data, further supporting the pedometer hypothesis.},
  journal = {Journal of Experimental Biology},
  keywords = {ants,cataglyphis,Cataglyphis,desert ant,Desert ant,navigation,Navigation,odometer,Odometer,step count,stride integration,Stride integration,walking behaviour,Walking behaviour},
  number = {2},
  pmid = {17210957}
}

@article{Wittlinger2013,
  title = {Homing Distance in Desert Ants, {{Cataglyphis}} Fortis, Remains Unaffected by Disturbance of Walking Behaviour and Visual Input},
  author = {Wittlinger, Matthias and Wolf, Harald},
  year = {2013},
  month = jan,
  volume = {107},
  pages = {130--136},
  publisher = {{Elsevier Ltd}},
  issn = {09284257},
  doi = {10.1016/j.jphysparis.2012.08.002},
  abstract = {Desert ants gauge walking distance by means of a stride integrator and, to a minor extent, by optic flow integration. With the present experiments we attempt to interfere with both, stride integration and optic flow input in order to reveal possible interactions of the two modes of odometry and further functional details of the stride integrator.We tried to impair stride integration by amputating two of the six walking legs. Amputation of left middle and right hind legs had especially severe effects since it left only the right front leg in one of the support tripods that are alternately used in walking. We tried to impair optic flow input - which is used for distance estimation to a minor extent - by covering both ventral eye halves. These two sets of manipulations were carried out in combination to study possible compensatory effects, for instance, of optic flow input in the case of an impaired stride integrator.Unexpectedly, none of the manipulations we carried out had significant effects on homing performance. This was true with regard to homing distance estimation (as determined by the centres of the ants' nest searches) and homing certainty (as determined by the search spreads). These results corroborate the surprising robustness of odometry by stride integration, and they indicate that leg proprioceptive feedback is used for stride integration. The question of a possible interaction of optic flow input and stride integration remains open. \textcopyright{} 2012 Elsevier Ltd.},
  journal = {Journal of Physiology Paris},
  keywords = {Cataglyphis,Desert ant,Distance estimation,Navigation,Odometry,Path integration},
  number = {1-2}
}

@article{Zollikofer1994,
  title = {{{STEPPING PATTERNS IN ANTS}} - {{INFLUENCE OF SPEED AND CURVATURE}}},
  author = {Zollikofer, C},
  year = {1994},
  month = jul,
  volume = {192},
  pages = {95--106},
  issn = {0022-0949},
  doi = {10.1242/jeb.192.1.95},
  abstract = {The locomotory behaviour of workers of 12 ant species belonging to four different genera (Formicinae: Cataglyphis, Formica, Lasius; Myrmicinae: Myrmica) was studied by filming individuals walking on smoked-glass plates. Subsequent multivariate analyses of footfall positions and walking kinematics revealed a set of constant features characterizing ant locomotion. The alternating tripod gait prevails over a wide range of speeds. The temporal rigidity of tripod coordination is paralleled by spatially rigid footfall patterns. Tripod geometry is preserved irrespective of speed and curvature. When walking around curves, tripods are rotated relative to the walking trajectory. Whereas stride length on the inner side of the curve is shortened, that on the outer side is independent of curvature.},
  file = {/Users/roaldarbol/Zotero/storage/VE4SGX32/Zollikofer - 1994 - STEPPING PATTERNS IN ANTS - INFLUENCE OF SPEED AND.pdf;/Users/roaldarbol/Zotero/storage/49JRIT9D/STEPPING-PATTERNS-IN-ANTS-INFLUENCE-OF-SPEED-AND.html},
  journal = {Journal of Experimental Biology},
  number = {1}
}

@article{Zollikofer1995,
  title = {Optical Scaling in Conspecific {{Cataglyphis}} Ants},
  author = {Zollikofer, C and Wehner, R and Fukushi, T},
  year = {1995},
  month = jan,
  volume = {198},
  pages = {1637--1646},
  issn = {0022-0949},
  doi = {10.1242/jeb.198.8.1637},
  abstract = {This study examines the effects of body size variation on the optical properties of the compound eyes of visually guided desert ants belonging to the genus Cataglyphis. Although linear head size may vary by a factor of 2 within conspecific workers and most optical parameters change accordingly, the extent of the visual field remains constant. Comparative measurements carried out on workers of three species (C. albicans, C. bicolor and C. fortis) and on reproductive females and males of one species (C. bicolor) show that the form (size and shape) of the visual field is highly characteristic for each caste/species. A constant visual field is realised by reciprocal scaling rules for the number of ommatidia and the angular spacing of ommatidia. While larger ants have more ommatidia per compound eye, interommatidial angles are reduced accordingly, thus giving rise to a constant visual field. Among conspecific ant workers, the relationship between spatial visual acuity and eye size is similar to that found in interspecific comparisons and reflects optical constraints imposed on the design of the compound eye. Mapping of spatial visual directions onto the compound eye surface reveals a characteristic, inhomogeneous distribution of interommatidial spacing, particularly a foveal band with increased visual acuity in the vertical direction. This 'visual stretch' viewing the horizon is similar to that found in a variety of flying insects. Although, among conspecific workers, both the number of ommatidia and the interommatidial angles vary with varying head size, the overall pattern of interommatidial spacing is maintained so that corresponding positions on the compound eye of small and large individuals look in equivalent directions in space. These findings are in accordance with the observation that the shape of the compound eye surface, as expressed by the radius of curvature along cross sections, is similar in small and large ants.},
  file = {/Users/roaldarbol/Zotero/storage/4NPZC2HM/Zollikofer et al. - 1995 - Optical scaling in conspecific Cataglyphis ants.pdf;/Users/roaldarbol/Zotero/storage/FZ44Q3XD/Optical-scaling-in-conspecific-Cataglyphis-ants.html},
  journal = {Journal of Experimental Biology},
  number = {8}
}


